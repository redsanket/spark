.. _metrics_simon_metricsv2:

**************
Hadoop Metrics
**************

Hadoop daemons and services are generally the scope for *metrics*, whereas
MapReduce applications are the scope for MapReduce *counters* (which are
collected for MapReduce tasks and aggregated for the whole job).

Metrics are grouped into named contexts â€“ e.g.:

A Hadoop daemon collects metrics in several contexts. For example, data nodes
collect metrics for the `"dfs"`, `"rpc"`` and `"jvm"` contexts.
The daemons that collect different metrics in Hadoop are listed as :



  

.. container:: twocol

    .. container:: leftside

       **Supported Contexts**

        * yarn
        * jvm
        * rpc
        * rpcdetailed
        * metricssystem
        * mapred
        * dfs
        * ugi 

    .. container:: rightside

       **Prefixes**
       
        * namenode
        * secondarynamenode
        * datanode
        * resourcemanager
        * nodemanager
        * mrappmaster
        * maptask
        * reducetask  


Sources
   are where the metrics are generated/updated.

Sinks
   consume the records generated by the metrics sources. A metrics system would
   poll the metrics sources periodically and pass the metrics records to metrics
   sinks.

Metrics2 framework is designed to collect and dispatch per-process metrics to
monitor the overall status of the Hadoop system. Producers register the metrics
sources with the metrics system, while consumers register the sinks. The
framework marshals metrics from sources to sinks based on (per source/sink)
configuration options.




.. _metrics_simon_metricsv2_configurations:

Configuration
=============


The Metrics2 framework uses the
`PropertiesConfiguration <http://commons.apache.org/proper/commons-configuration/userguide/howto_properties.html>`_
from the apache commons configuration library.


Sinks are specified in a configuration file with following syntax in properties
files (e.g., ":yahoo_github:`hadoop_configs - hadoop-metrics2.properties <hadoop/hadoop_configs/blob/y-branch-2.10/confSupport/templates/hadoop-metrics2.properties>`") as:


  .. code-block:: bash

     # syntax
     [prefix].[source|sink|jmx|].[instance].[option]

  
Example:

  .. code-block:: bash

     test.sink.mysink0.class=com.example.hadoop.metrics.MySink 
    
- `test`: prefix
- `mysink0`: is an instance name.

`DefaultMetricsSystem` would try to load `hadoop-metrics2-[prefix].properties`
first, and if not found, try the default `hadoop-metrics2.properties` in the
class path. |br|
Note, the `[instance]`` is an arbitrary name to uniquely identify a particular
sink instance. The asterisk `(*)` can be used to specify default options.

Example:

.. code-block:: bash

   # Here we define a file sink with the instance name "foo"
   *.sink.foo.class=org.apache.hadoop.metrics2.sink.FileSink
   # Now we specify the filename for every prefix/daemon that is used for
   namenode.sink.foo.filename=/tmp/namenode-metrics.out
   nodemanager.sink.foo.filename=/tmp/nodemanager-metrics.out
   secondarynamenode.sink.foo.filename=/tmp/secondarynamenode-metrics.out
   # We here define another file sink with a different instance name "bar"
   *.sink.bar.class=org.apache.hadoop.metrics2.sink.FileSink
   # Nodemanager can have two files to dump 
   nodemanager.sink.bar.filename=/tmp/nodemanager-metrics-bar.out


Here is an example set of `NodeManager` metrics that are dumped into the
`NodeManager` sink file:

.. code-block:: bash

  1349542623843 jvm.JvmMetrics: Context=jvm, ProcessName=NodeManager,
  SessionId=null, Hostname=ubuntu, MemNonHeapUsedM=11.877365,
  MemNonHeapCommittedM=18.25, MemHeapUsedM=2.9463196, MemHeapCommittedM=30.5,
  GcCountCopy=5, GcTimeMillisCopy=28, GcCountMarkSweepCompact=0,
  GcTimeMillisMarkSweepCompact=0, GcCount=5, GcTimeMillis=28, ThreadsNew=0,
  ThreadsRunnable=6, ThreadsBlocked=0, ThreadsWaiting=23, ThreadsTimedWaiting=2,
  ThreadsTerminated=0, LogFatal=0, LogError=0, LogWarn=0, LogInfo=0
  
  1349542623843 yarn.NodeManagerMetrics: Context=yarn, Hostname=ubuntu, AvailableGB=8
  
  1349542623843 ugi.UgiMetrics: Context=ugi, Hostname=ubuntu
  
  1349542623843 mapred.ShuffleMetrics: Context=mapred, Hostname=ubuntu
  
  1349542623844 rpc.rpc: port=42440, Context=rpc, Hostname=ubuntu,
  NumOpenConnections=0, CallQueueLength=0
  
  1349542623844 rpcdetailed.rpcdetailed: port=42440, Context=rpcdetailed, Hostname=ubuntu
  
  1349542623844 metricssystem.MetricsSystem: Context=metricssystem,
  Hostname=ubuntu, NumActiveSources=6, NumAllSources=6, NumActiveSinks=1,
  NumAllSinks=0, SnapshotNumOps=6, SnapshotAvgTime=0.16666666666666669


Filtering
=========


The framework supports 3 levels of filters: source, record and metrics names,
thus 6 ways to filter metrics with increasing cost (in terms of memory/CPU):

#. *Global source name filtering*: any sources with matching names are skipped
   for `getMetrics` calls.
#. *Per sink source name filtering*: any sources with matching names are skipped
   for `putMetrics` calls.
#. *Per source record filtering*: any records with matching names or tag values
   are skipped in the `MetricsBuilder.add*` calls in the `getMetrics` calls.
#. *Per sink record filtering*: any records with matching names or tag values are
   skipped for the `putMetrics` calls.
#. *Per source metrics filtering*: any metrics with matching names are skipped in
   the `Metric.sample*` calls in the `getMetrics` calls.
#. *Per sink metrics filtering*: any metrics with matching names are skipped in
   the iteration of the `MetricsRecord` in `putMetrics` calls.

These can be mixed and matched to optimize for lower total filtering cost if
necessary. This is done in the same properties file as described in
:numref:`metrics_simon_metricsv2_configurations`

Example-1:

.. code-block:: bash

    # Basic syntax: <prefix>.(source|sink).<instance>.<option>
    *.sink.file.class=org.apache.hadoop.metrics2.sink.FileSink
    *.source.filter.class=org.apache.hadoop.metrics2.filter.GlobFilter
    *.record.filter.class=${*.source.filter.class}
    *.metric.filter.class=${*.source.filter.class}
    *.period=10

    # Filter out any sources with names end with Details
    jobtracker.*.source.filter.exclude=*Details

    # Filter out records with names that matches foo* in the source named "rpc"
    jobtracker.source.rpc.record.filter.exclude=foo*

    # Filter out metrics with names that matches foo* for sink instance "file" only
    jobtracker.sink.file.metric.filter.exclude=foo*
    jobtracker.sink.file.filename=jt-metrics.out

    # Custom sink plugin
    jobtracker.sink.my.class=com.example.hadoop.metrics.my.MyPlugin
    # MyPlugin only handles metrics in "foo" context
    jobtracker.sink.my.context=foo


Example-2:


.. code-block:: bash

    mrappmaster.sink.foo.context=jvm
    # Define the classname used for filtering
    *.source.filter.class=org.apache.hadoop.metrics2.filter.GlobFilter
    *.record.filter.class=${*.source.filter.class}
    *.metric.filter.class=${*.source.filter.class}
    # Filter in any sources with names start with Jvm
    nodemanager.*.source.filter.include=Jvm*
    # Filter out records with names that matches foo* in the source named "rpc"
    nodemanager.source.rpc.record.filter.exclude=foo*
    # Filter out metrics with names that matches foo* for sink instance "file" only
    nodemanager.sink.foo.metric.filter.exclude=MemHeapUsedM

Development
===========

Metrics Source (Instrumentation)
--------------------------------

One might need to explicitly implement the
:hadoop_rel_doc:`MetricsSource <api/org/apache/hadoop/metrics2/MetricsSource.html>`
interface and override the `getMetrics` method and use the metrics builder API.


.. code-block:: java

    class MyMetricsSource implements MetricsSource {
     
      @Override
      public void getMetrics(MetricsBuilder builder) {
        builder.addRecord("foo")
          .addGauge("g0", "an integer gauge", 42)
          .addCounter("c0", "a long counter", 42L);
     
        // Typical metrics sources generate one record per snapshot.
        // We can add more records, which is not supported by annotations.
        builder.addRecord("bar")
          .addGauge("g1", "a float gauge", 42.0)
          .addCounter("c1", "a integer counter", 42);
      }
     
      public MyMetricSource registerWith(MetricsSystem ms) {
        return ms.register("MyMetrics", "MyMetrics description", this);
      }
    }

By using annotations, one can add simple metrics to any methods returning supported
types (int, long, float and double and their object counter parts) in any java
classes. |br|
A minimal metrics source:

.. code-block:: java

    // default record name is the class name
    // default context name is "default"
    @Metrics(context="bar")
    public class MyPojo {
      // Default name of metric is method name sans get
      // Default type of metric is gauge
      @Metric("An integer gauge named MyMetric")
      public int getMyMetric() { return 42; }
     
      // Recommended helper method
      public MyPojo registerWith(MetricsSystem ms) {
        return ms.register("MyPojo", "MyPojo metrics", this);
      }
    }

But for Large systems, it is recommended to use the following:

.. code-block:: java

  @Metrics(about="My metrics description", context="MyContext")
  class MyMetrics extends MyInstrumentation {

    @Metric("My gauge description") MutableGaugeInt gauge0;
    @Metric("My counter description") MutableCounterLong counter0;
    @Metric("My rate description") MutableRate rate0;

    @Override public void setGauge0(int value) { gauge0.set(value); }
    @Override public void incrCounter0() { counter0.incr(); }
    @Override public void addRate0(long elapsed) { rate0.add(elapsed); }
  }

In the above example:

MyInstrumentation
  This is usually an abstract class (or interface) to define an instrumentation
  interface (`incrCounter0` etc.) that allows different implementations. This
  could be a mechanism to allow different metrics systems to be used at runtime
  via configuration.
Mutable[Gauge*|Counter*|Rate]
  These are library classes to manage mutable metrics for implementations of
  metrics sources. They produce immutable gauge and counters
  (`Metric[Gauge*|Counter*]`) for downstream consumption (sinks) upon snapshot.
  The MutableRate in particular, provides a way to measure latency and
  throughput of an operation. In this particular case, it produces a long
  counter "Rate0NumOps" and double gauge "`Rate0AvgTime`" when snapshotted.

Metrics Sink (Plugin)
---------------------

Implementing a sink plugin with schema conversion (without a forest of if/switches):

.. code-block:: java

    public class EchoPlugin implements MetricsSink, MetricsVisitor {
     
      @Override // MetricsPlugin
      public void init(SubsetConfiguration conf) {
        // do plugin specific initialization here
      }
     
      @Override // MetricsSink
      public void putMetrics(MetricsRecord rec) {
        echoHeader(rec.name(), rec.context());
     
        for (MetricTag tag : rec.tags())
          echoTag(tag.getName(), tag.getValue());
       
        for (AbstractMetric metric : rec.metrics())
          metric.visit(this);
      }
     
      @Override // MetricsSink
      public void flush() {
        // do sink specific buffer management here
      }
     
      @Override // MetricsVisitor
      public void counter(MetricInfo info, int value) {
        echoCounterInt32(info.name(), value);
      }
     
      @Override // MetricsVisitor
      public void counter(MetricInfo info, long value) {
        echoCounterInt64(info.name(), value);
      }
     
      @Override // MetricsVisitor
      public void gauge(MetricInfo info, int value) {
        echoGaugeInt32(info.name(), value);
      }
     
      @Override // MetricsVisitor
      public void gauge(MetricInfo info, long value) {
        echoGaugeInt64(info.name(), value);
      }
     
      @Override // MetricsVisitor
      public void gauge(MetricInfo info, float value) {
        echoGaugeFp32(info.name(), value);
      }
     
      @Override // MetricsVisitor
      public void gauge(MetricInfo info, double value) {
        echoGaugeFp64(info.name(), value);
      }
    }

To use the Metric2s framework, the system needs to be initialized and sources
and sinks registered. Here is an example initialization:

.. code-block:: java

    public void init() {
      DefaultMetricsSystem.initialize("datanode");
      MetricsSystem.register(source1, "source1 description",
                                new MyMetricsSource());
      MetricsSystem.register(sink2, "sink2 description", new EchoPlugin());
    }
