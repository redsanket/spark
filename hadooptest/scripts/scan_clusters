#!/bin/bash

# for cluster in `IGOR_NS="grid_re.clusters";/home/y/bin/igor list -roles $IGOR_NS.*|grep $IGOR_NS.[a-zA-Z0-9]*$|cut -d "." -f3`;do echo -e "**********\n$cluster\n**********";hosts=`yinst range -ir "(@grid_re.clusters.$cluster)"|tr -s '\n' ','|sed -e  's/,$//'`;perl -e 'alarm shift @ARGV; exec @ARGV' 5 pdsh -w $hosts echo "Connected successfully";done

CHECK_FOR_ERROR=0
while :
do
    case "$1" in
	-a | --all)
            shift 1
	    ;;
	-c | --check_error)
            CHECK_FOR_ERROR=1
            shift 1
	    ;;
	-n | --no_error_checking)
            CHECK_FOR_ERROR=0
            shift 1
	    ;;
	-s | --skip)
            shift; SKIP_CLUSTERS="$1"; shift
            ;;
	*)  # No more options
	    break
	    ;;
    esac
done
CLUSTERS_PARAM=$*
CLUSTERS=${CLUSTERS_PARAM:=`NAMESPACE="grid_re"; ROLE="clusters";/home/y/bin/rocl -n $NAMESPACE -r $ROLE.*|grep $NAMESPACE.$ROLE.[a-zA-Z0-9]*$|cut -d "." -f3`}

function get_info() {
    host=$1

    # set -x
    # Get Hadoop version
    version=`ssh $host -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null hadoop version|head -1`

    # Get time stamp of last job
    # This can hang on hadoop fs -ls
    # ts=`ssh $host -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null "kinit -kt /homes/hadoopqa/hadoopqa.dev.headless.keytab hadoopqa@DEV.YGRID.YAHOO.COM; hadoop fs -ls -d /mapred/history/done|grep -v ^Found"`
    ts=`PDSH_SSH_ARGS_APPEND="-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" perl -e 'alarm shift @ARGV; exec @ARGV' 3 pdsh -t 30 -u 30 -w $host "kinit -kt /homes/hadoopqa/hadoopqa.dev.headless.keytab hadoopqa@DEV.YGRID.YAHOO.COM; /home/gs/hadoop/current/bin/hadoop fs -ls -d /mapred/history/done|grep -v ^Found"`

    time_stamp=`echo $ts|awk '{print $6, $7}'`
    # set +x
}

for cluster in $CLUSTERS; do
    echo "--------------------"
    echo cluster $cluster
    echo "--------------------"

    if [[ -n $SKIP_CLUSTERS ]] && [[ $SKIP_CLUSTERS =~ $cluster ]]; then 
	echo "Cluster $cluster is in the skip list, skip it..."
	continue
    fi

    hosts=`yinst range -ir "(@grid_re.clusters.$cluster)"`;
    if [[ $? -ne 0 ]]; then
	echo "Error: cluster $cluster has invalid role: $hosts"
	echo "Skipping cluster $cluster:"
	continue
    fi

    # Check the cluster hosts for bad nodes                                                                                                                                     
    echo "Check the cluster hosts for bad nodes"
    if [[ "$CHECK_FOR_ERROR" -eq 1 ]]; then
	hosts=`yinst range -ir "(@grid_re.clusters.$cluster)"|tr -s '\n' ','|sed -e  's/,$//'`;
        # perl -e 'alarm shift @ARGV; exec @ARGV' 5 pdsh -w $hosts "echo -n 'Connected successfully to ';hostname";
	set -x
	PDSH_SSH_ARGS_APPEND="-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" perl -e 'alarm shift @ARGV; exec @ARGV' 5 pdsh -t 30 -u 30 $PDSH_OPT -w $hosts "df -h";
	set +x
    fi

    version=""
    time_stamp=""

    # Get the Namenode and the ResourceManager
    echo "Get the namenode and resourcemanager"
    namenode=`yinst range -ir "(@grid_re.clusters.$cluster.namenode)"|head -1`;
    echo "NN=$namenode"
    echo "WEBUI: $cluster NN https://$namenode:50070/dfshealth.html"

    rm=`yinst range -ir "(@grid_re.clusters.$cluster.jobtracker)"|tr -s '\n' ','|sed -e  's/,$//'`;
    echo "RM=$rm"
    echo "WEBUI: $cluster RM https://$rm:8088/cluster"

    NN_STAT=$(PDSH_SSH_ARGS_APPEND="-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" perl -e 'alarm shift @ARGV; exec @ARGV' 5 pdsh -t 30 -u 30 $PDSH_OPT -w $namenode "ls /home/gs/hadoop/current/bin/hadoop");
    if [[ -n "$namenode" ]] && [[ "$NN_STAT" =~ "/home/gs/hadoop/current/bin/hadoop" ]]; then
	get_info $namenode
    else
	RM_STAT=$(PDSH_SSH_ARGS_APPEND="-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" perl -e 'alarm shift @ARGV; exec @ARGV' 5 pdsh -t 30 -u 30 $PDSH_OPT -w $rm "ls /home/gs/hadoop/current/bin/hadoop");
	if [[ -n "$rm" ]] && [[ "$RM_STAT" =~ "/home/gs/hadoop/current/bin/hadoop" ]]; then
	    get_info $rm
	else
	    echo "ERROR: unable to connect to or access hadoop on either the namenode or the resource manager - NN: $NN_STAT, RM: $RM_STAT"
	fi
    fi

    # HADOOP VERSION
    if [[ -n "$version" ]]; then 
        echo "Hadoop version for cluster $cluster: '$version'"
    else
	echo "Hadoop version for cluster $cluster: UNKNOWN"
    fi

    # TIME STAMP
    if [[ -n "$time_stamp" ]]; then 
        echo "Time stamp of last recorded job: '$time_stamp'"
    else
        echo "Time stamp of last recorded job: UNKNOWN"
    fi

    # Get Hadoop version from JMX
    # Version=`curl -s https://$namenode:50070/jmx?get=Hadoop:service=NameNode,name=NameNodeInfo::SoftwareVersion`
    # version=`echo $version|cut -d':' -f6|awk '{print $1}'`

    # Get time stamp of last job from url
    # last_job=`curl -s https://$rm:19888/jobhistory|grep job_|tail -1`
    # echo "Last recorded job in History Server:" `echo $last_job| cut -d, -f3,5,6,8`

    # Get time stamp of last job from log file
    # log_ts=`ssh $rm -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ls -lrt /home/gs/var/log/mapredqa/*|tail -1|awk '{print $6, $7, $8}'`

done

# console reboot
# auto file site-ops ticket


