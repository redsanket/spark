#!/usr/bin/env perl 

# ./deploySupport/ru_generatejob_cli --cluster sam --release hadoopXXX2X2Xlatest 
# ./deploySupport/ru_generatejob_cli --cluster sam --release hadoop_2_2_1_2_rc0

use strict;
use warnings;
use FindBin qw($Bin $Script);
use Test::More;
use File::Copy;
use File::Find::Rule;
use File::Basename;
use JSON qw( decode_json );
use Try::Tiny;
use Math::Round;
use Data::Dumper;

my %options=();

#
# Setup shell environment on a remote host
#

sub usage {
    my ($err_msg) = @_;
    print STDERR << "EOF";

  Usage: $Script -c cluster <option1> <values1> <option2> <values2> ...
-----------------------------------------------------------------------------------
The options
        -c|--cluster    <cluster name> : cluster name
        [ -f|           <conf file>         ] : hadooptest configuration file
        [ -w|workspace  <workspace>         ] : workspace
        [ -h|--help                         ] : help

Pass Through options
        [ -P<profile>                       ] : maven profile
        [ -Pclover -Djava.awt.headless=true ] : activate clover profile
        [ -X                                ] : maven debug output
        [ -Dthread.count=<threadcount>      ] : maven thread count

Example:
\$ run_hadooptest --cluster theoden
\$ run_hadooptest --cluster theoden -Dtest=TestSleepJobCLI
\$ run_hadooptest --cluster theoden --mvn -Dtest=TestSleepJobCLI
\$ run_hadooptest --cluster theoden --mvn -f /homes/hadoopqa/hadooptest.conf -Dtest=TestSleepJobCLI 
\$ run_hadooptest -c theoden -j -n -Dtest=hadooptest.regression.TestVersion
\$ run_hadooptest -c theoden -m -P jacoco -Dtest=TestVersion
\$ run_hadooptest -c theoden -m -P clover -Djava.awt.headless=true -Dtest=TestVersion
        
EOF
    die($err_msg) if ($err_msg);
    exit 0;
}

sub execute {
    my ($command) = @_;
    note($command);
    system($command);
}

my $cluster="sam";
my $started_time_begin;
my $admin_host="adm102.blue.ygrid.yahoo.com";

my $workspace = "$Bin/..";
my $username = getpwuid($<);

#
# Command line options processing
#
use Getopt::Long;
&Getopt::Long::Configure( 'pass_through');
my $result = 
GetOptions(\%options,
    "cluster|c=s"            => \$cluster,
    "started_time_begin|s=s" => \$started_time_begin,
    "id|i=s",
    "admin_host|a=s"         => \$admin_host,
    "workspace|w=s"          => \$workspace,
    "help|h|?"
    ) or usage(1);
usage() if $options{help};
usage("Invalid arguments!!!") if (!$result);
usage("ERROR: Required cluster value not defined!!!") if (!defined($cluster));

note("cluster='$cluster'");
note("started_time_begin='$started_time_begin'") if ($started_time_begin);
note("workspace='$workspace'");
note("admin host='$admin_host'"); 


my $rc=0;

note("====================================================================");
note("Check Hadoop Job Status After RU Deploy");
note("====================================================================");
# my $rm_host="gsbl90198.blue.ygrid.yahoo.com";
my $rm_host =`yinst range -ir "(\@grid_re.clusters.$cluster.jobtracker)"`;
chomp($rm_host);
my $rm_port="19888";

my ($command, $json_output);
my ($json_ref, $job_ref, $job_name, $job_shortname, $job_id, $job_state, $num_mappers, $num_files);

# http://hadoop.apache.org/docs/r2.3.0/hadoop-yarn/hadoop-yarn-site/HistoryServerRest.html
# If the Begin parameter is not specfied, it defaults to 0, and if the End parameter is not specified, it defaults to infinity.
# E.g. startedTimeBegin=1324256400&startedTimeEnd=1324303200
#   * user - user name
#   * state - the job state
#   * queue - queue name
#   * limit - total number of app objects to be returned
#   * startedTimeBegin - jobs with start time beginning with this time, specified in ms since epoch
#   * startedTimeEnd - jobs with start time ending with this time, specified in ms since epoch
#   * finishedTimeBegin - jobs with finish time beginning with this time, specified in ms since epoch
#   * finishedTimeEnd - jobs with finish time ending with this time, specified in ms since epoch
$command="curl -s -H 'Accept: application/json' -X GET 'http://$rm_host:$rm_port/ws/v1/history/mapreduce/jobs'";
$command .= "?startedTimeBegin=$started_time_begin" if ($started_time_begin);
note("$command");
$json_output=`$command`;
try {
	$json_ref = decode_json($json_output);
	# print Dumper $json_ref;
} catch {
	# print "$_\n" if $opts{debug};
	$json_output = "{}";
	$json_ref = decode_json($json_output);
};
my $jobs = $json_ref->{jobs}->{job};

my $num_failed_or_killed=0;
my $num_failed_or_killed_per_job=0;
my $num_jobs = scalar(@$jobs);
my $mbps;
use POSIX;
my $timeDelta;
my $file_size;
my $file_size_mb;
my $source;
my $target;
my $results;
my $file_sizes;
note("Number of jobs = '$num_jobs'");
note("job_name, start_time, time_delta, file_size, mbps, source, target");
note("=======================================================================");
foreach my $job (@$jobs) {
    $job_id = $job->{id};
    $command="curl -s -H 'Accept: application/json' -X GET 'http://$rm_host:$rm_port/ws/v1/history/mapreduce/jobs/$job_id'";
    # note("$command");
    $json_output=`$command`;
    # print("$json_output");
    try {
	$json_ref = decode_json($json_output);
    } catch {
	# print "$_\n" if $opts{debug};
	print $json_output;
	$json_output = "{}";
	$json_ref = decode_json($json_output);
    };
    # print Dumper $json_ref;
    $job_ref = $json_ref->{'job'};
    $job_name = $job_ref->{'name'};
    $job_state = $job_ref->{'state'};
    $num_mappers = $job_ref->{'mapsTotal'};
    if ($job_name =~ "distcp") {
	$job_shortname = $job_name;
	$job_shortname =~ s/distcp: file_//g;

	if ($job_shortname =~ /(.*)_(.*)_(.*)_(.*)/) {
	    $file_size = $1;
	    $num_files = $2;
	    $source = $3;
	    $target = $4;
	}
 	# note("num files = ".$num_files);

	$file_size_mb = $file_size;
	if ($file_size_mb =~ "G") {
	    $file_size_mb =~ s/\D//g;
	    $file_size_mb = $file_size_mb * 1024;
	} else {
	    $file_size_mb =~ s/\D//g;
	}
	# note("file size = ".$file_size_mb);

	# Convert from milliseconds to seconds
	$timeDelta = ($job_ref->{'finishTime'} - $job_ref->{'startTime'})/1000;
        $timeDelta = nearest(.1, $timeDelta); 

	# Convert megabyte to megabits
	$mbps = (8 * $file_size_mb*$num_files)/($timeDelta*$num_mappers);
        $mbps = nearest(.1, $mbps);

	note($job_shortname, ": (", $ file_size_mb, "MB * 8bits * ", $num_files, 
	     " files) / (", $timeDelta," sec * ", $num_mappers, " mappers) = ",
	     $mbps,"mbps");

	$job_shortname = $file_size."_".$source."_".$target;
	unless (defined($results->{$file_size})) {
	    $results->{$job_shortname} = ( $mbps );
	} else {
	    push(@{$results->{$job_shortname}}, $mbps);
	}

	if (defined($file_sizes->{$file_size_mb})) {
	    $job_shortname = $file_sizes->{$file_size_mb}.",".$job_shortname;
	    $file_sizes->{$file_size_mb} = $job_shortname;
	} else {
	    $file_sizes->{$file_size_mb} = $job_shortname;
	}
    }
}

# Write plot data to file
my $output_dir="$workspace/htf-common/target/surefire-reports/";
unless (-e $output_dir) {
    `mkdir -p $output_dir`;
}
note("output dir=$output_dir");
my $filename = "$output_dir/crosscolo_perf_plot.txt";
open(my $fh, '>', $filename) or die "Could not open file '$filename' $!";
my $colo;
my $colos;
my @keys;
for my $re ( sort {$a<=>$b} keys %$file_sizes) {
    # note("file_sizes: $re: value=".$file_sizes->{$re});
    # push(@keys, $file_sizes->{$re});
    for my $jobname (split(",", $file_sizes->{$re})) {
	# note("*** jobname=$jobname");

	if ($jobname =~ /(.*)_(.*)_(.*)/) {
            # note("size=$1, source=$2, target=$3");
	    $file_size = $1;
	    $source = $2;
	    $target = $3;
	}

        unless ((defined($colos->{$source})) && (defined($colos->{$target}))) {
	    $colo=`yinst range -ir "(\@grid_re.clusters.$source.namenode)"|grep -v '#'|head -1|cut -d. -f2`;
            chomp($colo);
            # note("colo=$colo");
	    $colos->{$source} = $colo;

	     $colo=`yinst range -ir "(\@grid_re.clusters.$target.namenode)"|grep -v '#'|head -1|cut -d. -f2`;
             chomp($colo);
             # note("colo=$colo");
             $colos->{$target} = $colo;
        }
        $source = $colos->{$source};
        $target = $colos->{$target};

	$jobname = $file_size."_".$source."_to_".$target;
        note("column name=$jobname");
	push(@keys, $jobname);
    }

}
print $fh join(",", @keys)."\n";

my @values;
for my $re ( sort {$a<=>$b} keys %$file_sizes) {
    for my $jobname (split(",", $file_sizes->{$re})) {
	# note("jobname=$jobname");
	push(@values, $results->{$jobname});
    }
}
print $fh join(",", @values)."\n";

system("cat $filename");

close $fh;

exit $num_failed_or_killed;


