#!/usr/bin/env perl 

use strict;
use warnings;
use FindBin qw($Bin $Script);
use Test::More;
use File::Copy;
use File::Find::Rule;
use File::Basename;

my %options=();

#
# Setup shell environment on a remote host
#

sub usage {
    my ($err_msg) = @_;
    print STDERR << "EOF";

  Usage: $Script -c cluster <option1> <values1> <option2> <values2> ...
-----------------------------------------------------------------------------------
The options
        -c|--cluster    <cluster name> : cluster name
        [ -f|           <conf file>         ] : hadooptest configuration file
        [ -j|--java                         ] : run tests via java directly instead of via maven
        [ -m|--mvn                          ] : run tests via maven instead of via java directly
        [ -build_coretest                   ] : build coretest
        [ -gdm                              ] : Run GDM tests without Hadoop being deployed to the node or cluster under test
        [ -spark                            ] : Install and setup a Spark environment on the gateway prior to running tests
        [ -n|--nopasswd                     ] : no password prompt
        [ -w|workspace  <workspace>         ] : workspace
        [ -a|--adm_box                      ] : The admin box to be used by the framework (adm103.blue.ygrid.yahoo.com is the default)
        [ -h|--help                         ] : help

Pass Through options
        [ -P<profile>                       ] : maven profile
        [ -Pclover -Djava.awt.headless=true ] : activate clover profile
        [ -X                                ] : maven debug output
        [ -Dthread.count=<threadcount>      ] : maven thread count
        [ -Dtest=<test>...                  ] : test suite name(s). use delimitor comma for mvn, and space for java

Example:
\$ run_hadooptest --cluster theoden
\$ run_hadooptest --cluster theoden -Dtest=TestSleepJobCLI
\$ run_hadooptest --cluster theoden --mvn -build_coretest --nopasswd -w `pwd` -t TestEndToEndPipes
\$ run_hadooptest --cluster theoden --mvn -Dtest=TestSleepJobCLI
\$ run_hadooptest --cluster theoden --mvn -f /homes/hadoopqa/hadooptest.conf -Dtest=TestSleepJobCLI 
\$ run_hadooptest -c theoden -j -n -Dtest=hadooptest.regression.TestVersion
\$ run_hadooptest -c theoden -m -P jacoco -Dtest=TestVersion
\$ run_hadooptest -c theoden -m -P clover -Djava.awt.headless=true -Dtest=TestVersion
        
EOF
    die($err_msg) if ($err_msg);
    exit 0;
}

sub execute {
    my ($command) = @_;
    note($command);
    system($command);
}

my $cluster;
my $conf = glob("~/hadooptest.conf");
my $use_mvn = 1;
my $build_coretest = 0;
my $gdm = 0;
my $spark = 0; 
my $workspace = "$Bin/..";
my $adm_box = "adm103.blue.ygrid.yahoo.com";
my $username = getpwuid($<);
my $nopasswd = ($username eq "hadoopqa") ? 1 : 0;
my $test;

#
# Command line options processing
#
use Getopt::Long;
&Getopt::Long::Configure( 'pass_through');
my $result = 
GetOptions(\%options,
    "cluster|c=s"        => \$cluster,
    "conf|f=s"           => \$conf,
    "mvn|m"              => sub { $use_mvn = 1 },
    "java|j"             => sub { $use_mvn = 0 },
    "build_coretest"     => \$build_coretest,
    "gdm"                => \$gdm,
    "spark"              => \$spark,
    "nopasswd|n"         => \$nopasswd,
    "workspace|w=s"      => \$workspace,
    "adm_box|a=s"        => \$adm_box, 
    "test|t=s"           => \$test,
    "help|h|?"
    ) or usage(1);
usage() if $options{help};
usage("Invalid arguments!!!") if (!$result);
usage("ERROR: Required cluster value not defined!!!") if (!defined($cluster));

note("cluster='$cluster'");
note("conf = $conf");
note("workspace='$workspace'");
note("adm box = $adm_box"); 
note("use_mvn='$use_mvn'");

my @tests = ($test) ? split(",", $test) : 
    (
     "hadooptest.regression.TestVersion",
     "hadooptest.regression.yarn.TestSleepJobAPI"
    );

my @classpath= (
    "/home/y/lib/jars/junit.jar",
    "/home/gs/gridre/yroot.$cluster/conf/hadoop/",
    "/home/y/etc/coretest/java/lib/coretest-1.0-SNAPSHOT.jar",
    "/tmp/RandomWriter.jar"    );

unless ($use_mvn) {
    push(@classpath, "$workspace/target/hadooptest-1.0-SNAPSHOT.jar");
    push(@classpath, "$workspace/target/hadooptest-1.0-SNAPSHOT-tests.jar");
}

my $hadoop_install="/home/gs/gridre/yroot.$cluster";
my @hadoop_jar_paths = (
    "$hadoop_install/share/hadoop/share/hadoop/common/lib",
    "$hadoop_install/share/hadoop-*/share/hadoop/common",
    "$hadoop_install/share/hadoop-*/share/hadoop/common/lib",
    "$hadoop_install/share/hadoop-*/share/hadoop/hdfs",
    "$hadoop_install/share/hadoop-*/share/hadoop/hdfs/lib",
    "$hadoop_install/share/hadoop-*/share/hadoop/yarn",
    "$hadoop_install/share/hadoop-*/share/hadoop/yarn/lib",
    "$hadoop_install/share/hadoop-*/share/hadoop/mapreduce",
    "$hadoop_install/share/hadoop-*/share/hadoop/hdfs"
    );

foreach my $path (@hadoop_jar_paths) {
    push(@classpath, `echo -en $path`.'/*');
};

note("CLASSPATH=".join(":",@classpath));

# TODO: long term this should move into the java test framework
execute("stty -echo; /usr/kerberos/bin/kinit $username\@DS.CORP.YAHOO.COM; stty echo")
    unless ($nopasswd);

my $pom_opt="-f pom-ci.xml help:active-profiles";
my $mvn_settings_opt="-gs $workspace/resources/yjava_maven/settings.xml.gw ";
my $java_lib_path="-Djava.library.path=/home/gs/gridre/yroot.$cluster/share/hadoop/lib/native/Linux-amd64-64/";
my @common_args = (
    "-DCLUSTER_NAME=$cluster",
    "-DWORKSPACE=$workspace",
    "-DADM_BOX=$adm_box", 
    "-Dhadooptest.config=$conf",
    join(" ", @ARGV)
    );

my $test_opt = ($use_mvn) ?
    "-Dtest=".join(",",@tests) :
    join(" ", @tests);

# TODO: investigate merging this in build.xml.
if ( grep( /^jacoco$/, @ARGV ) ) {
    # raw results directory
    my $jacoco_result_dir="/homes/hadoopqa/jacoco/results/latest";
    execute("rm -f $jacoco_result_dir/*");

    # final results directory
    my $jacoco_result_file="$workspace/target/jacoco.exec";
    execute("rm -f $jacoco_result_file");

    # misc results directory: 
    # $jacoco_result_dir="$workspace/data/exec";
    # execute("rm -f $jacoco_result_dir/*");
    # $jacoco_result_dir="$workspace/data/exec/jacoco.exec";
    # execute("rm -f $jacoco_result_dir");
}

# If the user has provided the -spark option to the script, install the Spark
# package so that we can run tests against the Spark jars.
if ($spark) {
    execute("yinst i yspark_yarn -br quarantine -live");
} 

my $hadoop_version;
my $cmd = "ls -l /home/gs/gridre/yroot.$cluster/share/hadoop|cut -d'>' -f2|cut -d'-' -f2";
note($cmd);
chomp($hadoop_version = `$cmd`);

# Fix for GDM to init the hadoop version since it won't be installed and we 
# expect hadoop 2 compatibility
if ($gdm) {
   $hadoop_version = "2.0";
} 

note("Hadoop version = '$hadoop_version'");
if ($use_mvn) {
    # RUN TESTS VIA MAVEN
    execute("/usr/local/bin/yinst install yjava_maven -br test -yes") unless (-e "/home/y/bin/mvn");

    if ($build_coretest) {
        execute("cd $workspace/../coretest; /home/y/bin/mvn package -DskipTests ");
        # execute("cd $workspace/../coretest; /home/y/bin/mvn install");
        execute("cd $workspace/../coretest; rm -f coretest_jar*.tgz; /home/y/bin/yinst_create -t nightly; yinst i coretest_jar*.tgz");
    }

    ############################################################################
    # Auto-set maven compile and runtime profiles for the corresponding 
    # Hadoop version if it is not set via external parameters. 
    ############################################################################
    # Check for maven compile profile for Hadoop. This is the compile time 
    # version reference. Should use the default profile here. 
    # E.g. Code on branch 23 will need to compile against H23, but may be able 
    # to run some tests on H2.0.
    # my $found_compile_profile = grep( /profile-compile/, @common_args);
    # my $hadoop_compile_profile;
    # unless ($found_compile_profile) {
    #     $hadoop_compile_profile = ($hadoop_version =~ "^0.23") ? "profile-compile-0.23.7" : "profile-compile-2.0";
    #     $pom_opt .= " -P$hadoop_compile_profile";
    # }

    # Check for maven runtime profile for Hadoop. This should correspod to the
    # Hadoop version deployed on the cluster under test.
    my $found_runtime_profile = grep( /profile-runtime/, @common_args);
    my $hadoop_runtime_profile;
    unless ($found_runtime_profile) {
        $hadoop_runtime_profile = ($hadoop_version =~ "^0.23") ? "profile-runtime-0.23.7" : "profile-runtime-2.0";
        $pom_opt .= " -P$hadoop_runtime_profile";
    }

    my $hadoop_share = "/home/gs/gridre/yroot.$cluster/share/hadoop-$hadoop_version/share/hadoop/";
    if ($gdm) {
        # If the -gdm option is specified to the script, we want to 
        # run with the gdm-deployed Hadoop 2.0 jars, instead of relying
        # on any cluster deployment of the Hadoop jar
        $hadoop_version = "2.0.5.0.1306301601";
        $hadoop_share = "/grid/0/yroot/var/yroots/console/home/y/libexec/prod_hadoop_versions/$hadoop_version/share/hadoop-$hadoop_version/share/hadoop/";
        
        # Set up a rule to use to search the GDM Hadoop jars base dir
        my $base_dir = "/grid/0/yroot/var/yroots/console/home/y/libexec/prod_hadoop_versions/";
        my $find_rule = File::Find::Rule->new;

        # Do not descend past the first level
        $find_rule->maxdepth(1);

        # Only return directories
        $find_rule->directory;

        # Apply the rule and retrieve the subdirectories, which should be the
        # directories named by Hadoop version.
        my @sub_dirs = $find_rule->in($base_dir);

        # Print out the name of each directory on its own line
        print "\nGDM Hadoop dependency directories are:\n";
        print join("\n", @sub_dirs);
        print "\n\n";
        
        # Get the individual directory version names
        my @basedirs;
        foreach my $dirname (@sub_dirs) {
            push @basedirs, basename($dirname);
        };
        
        # inverse alphabetical sort the names so most recent version comes first
        @basedirs = reverse(sort @basedirs);
        
        # pick the most recent 2.0 version to use for Hadoop dependencies
        foreach my $basedir (@basedirs) {
            if ($basedir =~ m/^2\.(.*)/) {
                print "\n\nSetting GDM Hadoop dependencies to Hadoop version $basedir\n\n";
                $hadoop_version = $basedir;
                $hadoop_share = "/grid/0/yroot/var/yroots/console/home/y/libexec/prod_hadoop_versions/$hadoop_version/share/hadoop-$hadoop_version/share/hadoop/";
                last;
            }
        } 
    }
    
    ############################################################################
    # Execute the maven command
    ############################################################################
    execute("CLUSTER=$cluster ".
            "HADOOP_VERSION=$hadoop_version ".
            "HADOOP_INSTALL=$hadoop_install ".
            "HADOOP_SHARE=$hadoop_share ".
            "/home/y/bin/mvn $pom_opt $mvn_settings_opt clean test -DfailIfNoTests=false ".
            join(" ", @common_args)." ".
            $test_opt);

} else {

    # Need to compile the hadooptest jar if it doesn't exist.
    unless (-e "$workspace/target/hadooptest-1.0-SNAPSHOT.jar") {
        execute("/home/y/bin/mvn clean package -DskipTests");
    }

    # RUN TESTS VIA JAVA
    execute("/home/y/bin/java -cp ".
            join(":",@classpath)." ".
            join(" ",@common_args)." ".
            "$java_lib_path ".
            "org.junit.runner.JUnitCore ".
            $test_opt);
}

# Write test results in TAP format to /homes/hadoopqa

# Copy the finger print file if it exists (so this test execution can be tied
# with other related Jenkins jobs. 
# E.g "/home/y/var/builds/workspace/NightlyHadoopQEAutomation-23
my $result_root_dir = "/homes/hadoopqa/hudson_artifacts/";
$result_root_dir .= ($hadoop_version =~ /^0.23/) ? "hudson_artifacts-0.23" : "hudson_artifacts-2.0";
my $fingerprint = $result_root_dir."/artifacts.stamp";
if (-e $fingerprint) {
    note("copy fingerprint file '$fingerprint' to workspace '$workspace':");
    copy($fingerprint,"$workspace/artifacts.stamp");
} else {
    note("Found no upstream fingerprint file '$fingerprint' to copy to workspace '$workspace':");
}
