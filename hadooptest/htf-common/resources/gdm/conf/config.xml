<?xml version="1.0" encoding="UTF-8"?>
<!--
        11 Oct 2012
        This sets the base configuration params for the GDM installation to
        run tests against. There is one dependnecy on the test target and
        that is we have to add the headless qe user to the console's tomcat
        webapp's bouncer auth list, this is needed to allow the console to 
        accept programmatic http requests from the qe tests.    

        The usage is to ensure CONSOLE_HOST and CONSOLE_PORT are correctly
        set, or that the yinst installation sets these parameters.
-->
<config>
  <hostconfig>
    <console>
      <test_environment_type>$(TEST_EXECUTION_ENV)</test_environment_type> <!-- value "oneNode" for qe or dev environment and value "staging" for staging environment -->
	  <base_url>http://$(CONSOLE_HOST):$(CONSOLE_PORT)</base_url>
	  <staging_console_url>http://$(STAGING_CONSOLE_HOST):$(STAGING_CONSOLE_PORT)</staging_console_url>
	  <deployment-suffix-name>$(MY_SUFFIX)</deployment-suffix-name>
	  <crcValue>$(CRC_VALUE)</crcValue>
	  <performance-iteration-value>$(NUMBER_OF_ITERATION)</performance-iteration-value>
	  <stress-noOfDataSets>$(NUMBER_OF_DATASETS)</stress-noOfDataSets>
	  <stress-noOfinstances>$(NUMBER_OF_INSTANCES_PER_DATASET)</stress-noOfinstances>
	  <stress-filesInInstance>$(NUMBER_OF_INSTANCE_FILES_INSTANCE)</stress-filesInInstance>
      <actions>/console/rest/config/dataset/actions</actions>
      <datasets>
        <view>
          <resource>/console/api/datasets/view</resource>
        </view>
        <clone>
          <resource>/console/rest/config/dataset</resource>
        </clone>
        <unterminate>
          <resource>/console/rest/config/dataset/actions</resource>
        </unterminate>
      </datasets>
      <datasource>
        <view>
          <resource>/console/api/datasets/view</resource>
        </view>
        <clone>
          <resource>/console/rest/config/datasource</resource>
        </clone>
        <unterminate>
          <resource>/console/rest/config/dataset/actions</resource>
        </unterminate>
      </datasource>
      <workflows>
        <running>
          <resource>/console/api/workflows/running</resource>
        </running>
        <completed>
          <resource>/console/api/workflows/completed</resource>
          <param>starttime</param>
          <param>endtime</param>
          <param>datasetname</param>
          <param>instancessince</param>
        </completed>
        <failed>
          <resource>/console/api/workflows/failed</resource>
          <param>starttime</param>
          <param>endtime</param>
          <param>datasetname</param>
          <param>instancessince</param>
        </failed>
        <stepexecutions>
          <resource>/console/api/workflows/WORKFLOW_EXECUTION_ID/view</resource>
          <param>facet</param>
          <param>colo</param>
        </stepexecutions>
        <status>/console/api/workflows/WORKFLOW_EXECUTION_ID/view?facet=acquisition</status>
        <!--&colo=gq1-->
      </workflows>
    </console>
  </hostconfig>
    <testconfig>
    <REG_smFeed_AcqReplRet_FDI_HDFS_SingleDate>
      <basedatasets>REG_smFeed_AcqReplRet_FDI_HDFS_SingleDate</basedatasets>
    </REG_smFeed_AcqReplRet_FDI_HDFS_SingleDate>
    <VerifyAcqRepRetWorkFlowExecutionSingleDate>
      <basedataset>VerifyAcqRepRetWorkFlowExecutionSingleDate</basedataset>
      <waitTimeForRepostoryUpdateInMs>45000</waitTimeForRepostoryUpdateInMs>
      <waitTimeBeforeWorkflowPollingInMs>180000</waitTimeBeforeWorkflowPollingInMs>
      <waitTimeBetweenWorkflowPollingInMs>60000</waitTimeBetweenWorkflowPollingInMs>
      <timeoutInMs>1200000</timeoutInMs>
    </VerifyAcqRepRetWorkFlowExecutionSingleDate>
    <ABFTest>
        <source1>elrond</source1>
        <target1>omegap1</target1>
        <hcatTableName>ABFTest01</hcatTableName>
    </ABFTest>
    <HCatSchemaUpdateTest>
        <grid1>omegap1</grid1>
    </HCatSchemaUpdateTest>
    <IntegrationTest>
    	<sourceCluster>$(SOURCE_CLUSTER)</sourceCluster>
    	<destinationCluster>$(DEST_CLUSTER)</destinationCluster>
    	<duration>$(DURATION)</duration> <!-- duration in days -->
    	<enable-hcat>$(ENABLE_HCAT)</enable-hcat>
    	<frequency>$(HOURLY)</frequency><!--  hourly --> 
    </IntegrationTest>
    <TestWatchForDataDrop>
		<clusterName>$(CLUSTER_NAME)</clusterName>
		<pipeLineName>$(PIPELINE_NAME)</pipeLineName>
		<stackComponents>$(STACK_COMPONENT_TEST_LIST)</stackComponents>
		<duration>$(DURATION)</duration> <!-- duration in days -->
		<frequency>$(FREQUENCY)</frequency>
		<testType>$(TEST_TYPE)</testType>
		<dataSetPattern>$(PATTERN)</dataSetPattern> <!-- hourly -->
		<oozieHostName>$(OOZIE_HOST_NAME)</oozieHostName>
		<hcatHostName>$(HCAT_HOST_NAME)</hcatHostName>
		<pullOozieJobLength>$(PULL_OOZIE_JOB_LENGTH)</pullOozieJobLength> 
		<nameNodeHostName>$(NAME_NODE_HOST_NAME)</nameNodeHostName>
		<pigHostName>$(PIG_HOST_NAME)</pigHostName>
		<hbaseClusterName>$(HBASE_CLUSTERNAME)</hbaseClusterName>
		<hbaseMasterHostName>$(HBASE_MASTER_HOST_NAME)</hbaseMasterHostName>
		<hbaseMasterPort>$(HBASE_MASTER_PORT)</hbaseMasterPort>
		<hbaseRegionalServerPort>$(HBASE_REGIONAL_SERVER_PORT)</hbaseRegionalServerPort>
		<gateWayName>$(GATEWAY_HOST_NAME)</gateWayName>
		<hiveHostName>${HIVE_HOST_NAME}</hiveHostName>
    </TestWatchForDataDrop>
  </testconfig>
  <auth>
    <usr>hitusr_1</usr>
    <pp>NOT_VALID</pp>
    <nonAdminUser>hitusr_2</nonAdminUser>
    <nonAdminPassWord>NOT_VALID</nonAdminPassWord>
  </auth>
</config>
